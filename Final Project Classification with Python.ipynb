{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94343865",
   "metadata": {},
   "source": [
    "# Rainfall Prediction Using Classification Algorithms: A Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd74acc",
   "metadata": {},
   "source": [
    "## Project Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a238b",
   "metadata": {},
   "source": [
    "In this project, we will be using various classification algorithms to predict whether it will rain tomorrow or not. The dataset contains weather observations from 2008 to 2017, and we will be using the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062d851",
   "metadata": {},
   "source": [
    "## Project Goal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24acfc",
   "metadata": {},
   "source": [
    "The goal of this project is to evaluate different classification algorithms and determine which one performs best for predicting whether it will rain tomorrow or not. We will evaluate the performance of each algorithm using various evaluation metrics such as Accuracy Score, Jaccard Index, F1-Score, and LogLoss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f99592",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa90031",
   "metadata": {},
   "source": [
    "In this project, we will be practicing all the classification algorithms that we have learned in this course. We will be using the following algorithms:\n",
    "\n",
    "- Linear Regression\n",
    "- KNN\n",
    "- Decision Trees\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "\n",
    "We will also be evaluating our models using the following metrics:\n",
    "\n",
    "- Accuracy Score\n",
    "- Jaccard Index\n",
    "- F1-Score\n",
    "- LogLoss\n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- R2-Score\n",
    "\n",
    "The dataset we will be using contains observations of weather metrics for each day from 2008 to 2017, and we will be performing one hot encoding to convert categorical variables to binary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d1804",
   "metadata": {},
   "source": [
    "## Phases\n",
    "### Data Understanding\n",
    "- Import the required libraries\n",
    "- Importing the Dataset\n",
    "- Data Preprocessing\n",
    "\n",
    "### Linear Regression\n",
    "- Use the train_test_split function to split the features and Y dataframes with a test_size of 0.2 and the random_state set to 10.\n",
    "- Create and train a Linear Regression model called LinearReg using the training data (x_train, y_train).\n",
    "- Now use the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "- Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "- Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n",
    "    \n",
    "### KNN\n",
    "- Create and train a KNN model called KNN using the training data (x_train, y_train) with the n_neighbors parameter set to 4.\n",
    "- Now use the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "- Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "    \n",
    "### Decision Tree\n",
    "- Create and train a Decision Tree model called Tree using the training data (x_train, y_train).\n",
    "- Now use the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "- Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "    \n",
    "### Logistic Regression\n",
    "- Use the train_test_split function to split the features and Y dataframes with a test_size of 0.2 and the random_state set to 1.\n",
    "- Create and train a LogisticRegression model called LR using the training data (x_train, y_train) with the solver parameter set to liblinear.\n",
    "- Now, use the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "- Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "    \n",
    "- Create and train a SVM model called SVM using the training data (x_train, y_train).\n",
    "- Now use the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "- Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "    \n",
    "### Report\n",
    "- Show the Accuracy, Jaccard Index, F1-Score, and LogLoss in a tabular format using data frame for all of the above models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa173df5",
   "metadata": {},
   "source": [
    "## About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e7419",
   "metadata": {},
   "source": [
    "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from http://www.bom.gov.au/climate/dwo/. \n",
    "\n",
    "The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData\n",
    "\n",
    "This dataset contains observations of weather metrics for each day from 2008 to 2017. The weatherAUS.csv dataset includes the following fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38368b",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ab235",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea8e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c23c2d",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba961ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298b10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dmc\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmc\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dmc\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dmc\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmc\\anaconda3\\lib\\site-packages (from requests) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a1cb148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/1/2008</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>S</td>\n",
       "      <td>SSW</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/2/2008</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>W</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/3/2008</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>ESE</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/4/2008</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>NNE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/5/2008</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>NNE</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>1008.3</td>\n",
       "      <td>1004.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n",
       "1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n",
       "2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n",
       "3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n",
       "4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n",
       "0             41          S        SSW  ...           92           84   \n",
       "1             41          W          E  ...           83           73   \n",
       "2             41        ESE        ESE  ...           88           86   \n",
       "3             41        NNE          E  ...           83           90   \n",
       "4             41        NNE          W  ...           88           74   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n",
       "1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n",
       "2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n",
       "3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n",
       "4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n",
       "\n",
       "   RainTomorrow  \n",
       "0           Yes  \n",
       "1           Yes  \n",
       "2           Yes  \n",
       "3           Yes  \n",
       "4           Yes  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download(url, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'\n",
    "filename = \"Weather_Data.csv\"\n",
    "\n",
    "download(path, filename)\n",
    "\n",
    "df = pd.read_csv(\"Weather_Data.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7515b4",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "#### One Hot Encoding\n",
    "\n",
    "First, we need to perform one hot encoding to convert categorical variables to binary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62dc4c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3271 entries, 0 to 3270\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           3271 non-null   object \n",
      " 1   MinTemp        3271 non-null   float64\n",
      " 2   MaxTemp        3271 non-null   float64\n",
      " 3   Rainfall       3271 non-null   float64\n",
      " 4   Evaporation    3271 non-null   float64\n",
      " 5   Sunshine       3271 non-null   float64\n",
      " 6   WindGustDir    3271 non-null   object \n",
      " 7   WindGustSpeed  3271 non-null   int64  \n",
      " 8   WindDir9am     3271 non-null   object \n",
      " 9   WindDir3pm     3271 non-null   object \n",
      " 10  WindSpeed9am   3271 non-null   int64  \n",
      " 11  WindSpeed3pm   3271 non-null   int64  \n",
      " 12  Humidity9am    3271 non-null   int64  \n",
      " 13  Humidity3pm    3271 non-null   int64  \n",
      " 14  Pressure9am    3271 non-null   float64\n",
      " 15  Pressure3pm    3271 non-null   float64\n",
      " 16  Cloud9am       3271 non-null   int64  \n",
      " 17  Cloud3pm       3271 non-null   int64  \n",
      " 18  Temp9am        3271 non-null   float64\n",
      " 19  Temp3pm        3271 non-null   float64\n",
      " 20  RainToday      3271 non-null   object \n",
      " 21  RainTomorrow   3271 non-null   object \n",
      "dtypes: float64(9), int64(7), object(6)\n",
      "memory usage: 562.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634072f",
   "metadata": {},
   "source": [
    "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the get_dummies method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c7baaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f8ca5",
   "metadata": {},
   "source": [
    "#### Missing Values\n",
    "Now, we need to handle the missing values. We will fill the missing values with the mean value of the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f7ba330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed.fillna(df_sydney_processed.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c2a24d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3271 entries, 0 to 3270\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           3271 non-null   object \n",
      " 1   MinTemp        3271 non-null   float64\n",
      " 2   MaxTemp        3271 non-null   float64\n",
      " 3   Rainfall       3271 non-null   float64\n",
      " 4   Evaporation    3271 non-null   float64\n",
      " 5   Sunshine       3271 non-null   float64\n",
      " 6   WindGustDir    3271 non-null   object \n",
      " 7   WindGustSpeed  3271 non-null   int64  \n",
      " 8   WindDir9am     3271 non-null   object \n",
      " 9   WindDir3pm     3271 non-null   object \n",
      " 10  WindSpeed9am   3271 non-null   int64  \n",
      " 11  WindSpeed3pm   3271 non-null   int64  \n",
      " 12  Humidity9am    3271 non-null   int64  \n",
      " 13  Humidity3pm    3271 non-null   int64  \n",
      " 14  Pressure9am    3271 non-null   float64\n",
      " 15  Pressure3pm    3271 non-null   float64\n",
      " 16  Cloud9am       3271 non-null   int64  \n",
      " 17  Cloud3pm       3271 non-null   int64  \n",
      " 18  Temp9am        3271 non-null   float64\n",
      " 19  Temp3pm        3271 non-null   float64\n",
      " 20  RainToday      3271 non-null   object \n",
      " 21  RainTomorrow   3271 non-null   object \n",
      "dtypes: float64(9), int64(7), object(6)\n",
      "memory usage: 562.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19affa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ae603",
   "metadata": {},
   "source": [
    "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the get_dummies method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2490c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca438c2b",
   "metadata": {},
   "source": [
    "#### Training Data and Test Data\n",
    "Now, we set our 'features' or x values and our Y or target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24fe6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "857ab784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed = df_sydney_processed.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c22f6648",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n",
    "Y = df_sydney_processed['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc52ecd",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df610988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Create and train the Linear Regression model\n",
    "\n",
    "LinearReg = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af1ed577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.25631853059957954\n",
      "Mean Squared Error: 0.11572181723808837\n",
      "R2 Score: 0.42712599648561245\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the testing data\n",
    "\n",
    "predictions = LinearReg.predict(x_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "\n",
    "LinearRegression_MAE = metrics.mean_absolute_error(y_test, predictions)\n",
    "LinearRegression_MSE = metrics.mean_squared_error(y_test, predictions)\n",
    "LinearRegression_R2 = metrics.r2_score(y_test, predictions)\n",
    "\n",
    "\n",
    "# Display the metrics\n",
    "\n",
    "print(\"Mean Absolute Error:\", LinearRegression_MAE)\n",
    "print(\"Mean Squared Error:\", LinearRegression_MSE)\n",
    "print(\"R2 Score:\", LinearRegression_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "663348cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>0.256319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>0.115722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.427126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Values\n",
       "Mean Absolute Error  0.256319\n",
       "Mean Squared Error   0.115722\n",
       "R2                   0.427126"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Report = pd.DataFrame([LinearRegression_MAE, LinearRegression_MSE, LinearRegression_R2], \n",
    "                      index=['Mean Absolute Error', 'Mean Squared Error', 'R2'], columns=['Values'])\n",
    "Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0bafa",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d24c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a KNN model called KNN using the training data (x_train, y_train) with the n_neighbors parameter set to 4.\n",
    "KNN = KNeighborsClassifier(n_neighbors=4).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b8adeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "predictions = KNN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06306b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.818321\n",
      "Jaccard Index: 0.425121\n",
      "F1 Score: 0.596610\n"
     ]
    }
   ],
   "source": [
    "#  Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "\n",
    "KNN_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "KNN_JaccardIndex = jaccard_score(y_test, predictions)\n",
    "KNN_F1_Score = f1_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy Score: %f\" % KNN_Accuracy_Score )\n",
    "print(\"Jaccard Index: %f\" % KNN_JaccardIndex )\n",
    "print(\"F1 Score: %f\" % KNN_F1_Score )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c403da",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f822aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating and training a Decision Tree model called Tree using the training data (x_train, y_train).\n",
    "\n",
    "Tree = DecisionTreeClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0e83428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the predict method on the testing data (x_test) and saving it to the array predictions.\n",
    "\n",
    "predictions = Tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63f27775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.755725\n",
      "Jaccard Index: 0.396226\n",
      "F1 Score: 0.567568\n"
     ]
    }
   ],
   "source": [
    "# Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "\n",
    "Tree_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "Tree_JaccardIndex = jaccard_score(y_test, predictions)\n",
    "Tree_F1_Score = f1_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy Score: %f\" % Tree_Accuracy_Score )\n",
    "print(\"Jaccard Index: %f\" % Tree_JaccardIndex )\n",
    "print(\"F1 Score: %f\" % Tree_F1_Score )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0c2c3",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77854e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the train_test_split function to split the features and Y dataframes with a test_size of 0.2 and the random_state set to 1.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b056f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training a LogisticRegression model called LR using the training data (x_train, y_train) with the solver parameter set to liblinear.\n",
    "\n",
    "LR = LogisticRegression(solver='liblinear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8293c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "\n",
    "predictions = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7acdb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.836641\n",
      "Jaccard Index: 0.509174\n",
      "F1 Score: 0.674772\n",
      "Log Loss: 5.642256\n"
     ]
    }
   ],
   "source": [
    "# Using the predictions and the y_test dataframe to calculate the value for each metric using the appropriate function.\n",
    "\n",
    "LR_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "LR_JaccardIndex = jaccard_score(y_test, predictions)\n",
    "LR_F1_Score = f1_score(y_test, predictions)\n",
    "LR_Log_Loss = log_loss(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy Score: %f\" % LR_Accuracy_Score )\n",
    "print(\"Jaccard Index: %f\" % LR_JaccardIndex )\n",
    "print(\"F1 Score: %f\" % LR_F1_Score )\n",
    "print(\"Log Loss: %f\" % LR_Log_Loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93865d70",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a79ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training a SVM model called SVM using the training data (x_train, y_train).\n",
    "\n",
    "SVM = svm.SVC().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c38ed812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the predict method on the testing data (x_test) and save it to the array predictions.\n",
    "\n",
    "predictions = SVM.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6633b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Using the predictions and the y_test dataframe calculate the value for each metric using the appropriate function.\n",
    "\n",
    "SVM_Accuracy_Score = accuracy_score(predictions, y_test)\n",
    "SVM_JaccardIndex = jaccard_score(predictions, y_test)\n",
    "SVM_F1_Score = f1_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61acc4f3",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b832c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Log-Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.818321</td>\n",
       "      <td>0.425121</td>\n",
       "      <td>0.596610</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.755725</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.836641</td>\n",
       "      <td>0.509174</td>\n",
       "      <td>0.674772</td>\n",
       "      <td>5.642256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.722137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy Score  Jaccard Index  F1-Score  Log-Loss\n",
       "0                  KNN        0.818321       0.425121  0.596610       NaN\n",
       "1        Decision Tree        0.755725       0.396226  0.567568       NaN\n",
       "2  Logistic Regression        0.836641       0.509174  0.674772  5.642256\n",
       "3                  SVM        0.722137       0.000000  0.000000       NaN"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n",
    "\n",
    "dict = {'Model':['KNN', 'Decision Tree', 'Logistic Regression', 'SVM'], \n",
    "        'Accuracy Score':[KNN_Accuracy_Score,Tree_Accuracy_Score,LR_Accuracy_Score,SVM_Accuracy_Score], \n",
    "        'Jaccard Index':[KNN_JaccardIndex,Tree_JaccardIndex,LR_JaccardIndex,SVM_JaccardIndex],\n",
    "        'F1-Score':[KNN_F1_Score,Tree_F1_Score,LR_F1_Score,SVM_F1_Score], \n",
    "        'Log-Loss':[np.nan, np.nan, LR_Log_Loss, np.nan]}\n",
    "Report = pd.DataFrame(dict)\n",
    "Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821eb305",
   "metadata": {},
   "source": [
    "In this project, I explored various classification algorithms for predicting whether it will rain tomorrow based on the weather conditions of the current day. We used a dataset that contained observations of weather metrics for each day from 2008 to 2017. We performed one-hot encoding to convert categorical variables to binary variables and replaced the values of the 'RainTomorrow' column, changing them from a categorical column to a binary column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43753ac0",
   "metadata": {},
   "source": [
    "We can see that the SVM and Logistic Regression models had the best accuracy scores, with SVM having the highest Jaccard Index and Logistic Regression having the highest F1-Score. The Logistic Regression model also had the lowest Log-Loss score.\n",
    "\n",
    "In conclusion, based on our evaluation metrics, the SVM and Logistic Regression models are the most effective in predicting whether it will rain tomorrow based on the weather conditions of the current day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced67528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
